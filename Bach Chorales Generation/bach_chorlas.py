# -*- coding: utf-8 -*-
"""Bach_Chorlas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Klp3UPchHjNpgNf2mlvb1K55BZp8x0fZ
"""

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Input, Flatten, BatchNormalization
import tensorflow_datasets as tfds
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt

import tarfile

with tarfile.open('jsb_chorales.tgz','r') as f:
  f.extractall()

jsb_chorales_dir = './jsb_chorales'

train_files = sorted(tf.io.gfile.glob(os.path.join(jsb_chorales_dir,'train/*.csv')))
test_files = sorted(tf.io.gfile.glob(os.path.join(jsb_chorales_dir,'test/*.csv')))
valid_files = sorted(tf.io.gfile.glob(os.path.join(jsb_chorales_dir,'valid/*.csv')))

def load_file(filepaths):
  return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]

train_chorales = load_file(train_files)
test_chorales = load_file(test_files)
valid_chorales = load_file(valid_files)
train_chorales[0]

notes = set()
for chorales in (train_chorales,valid_chorales, test_chorales):
  for chorale in chorales:
    for chord in chorale:
      notes |= set(chord)
n_notes = len(notes)
min_note = min(notes-{0})
max_note = max(notes)

assert min_note == 36
assert max_note == 81

from IPython.display import Audio

def notes_to_frequency(notes):
  return 2 ** ((np.array(notes) - 69) / 12) * 440

def frequencies_to_samples(frequencies, tempo, sample_rate):
  note_duration = 60/tempo
  frequencies = np.round(note_duration * frequencies)/note_duration
  n_samples = int(note_duration * sample_rate)
  time = np.linspace(0,note_duration,n_samples)
  sin_waves = np.sin(2 * np.pi * frequencies.reshape(-1,1) * time)
  sin_waves *= (frequencies > 9.).reshape(-1,1)
  return sin_waves.reshape(-1)

def chord_to_sample(chords,tempo, sample_rate):
  freqs = notes_to_frequency(chords)
  freqs = np.r_[freqs, freqs[-1:]]
  merged = np.mean([frequencies_to_samples(melody,tempo,sample_rate)
                    for melody in freqs.T], axis=0)
  n_fade_out_samples = sample_rate * 60 // tempo
  fade_out = np.linspace(1.,0.,n_fade_out_samples) ** 2
  merged[-n_fade_out_samples:] *= fade_out
  return merged

def play_chords(chords,tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):
  samples = amplitude * chord_to_sample(chords,tempo,sample_rate)
  if filepath:
    from scipy.io import wavfile
    samples = (2**15 * samples).astype(np.int16)
    wavfile.write(filepath, sample_rate, samples)
    return display(Audio(filepath))
  else:
    return display(Audio(samples,rate=sample_rate))

for index in range(3):
    play_chords(train_chorales[index])

def create_target(batch):
  x = batch[:, :-1]
  y = batch[:,1:]
  return x,y

def preprocess(window):
  window = tf.where(window==0, window,window-min_note+1)
  print(f"window Shape: {window.shape}")
  return tf.reshape(window,[-1])

def bach_dataset(chorales,batch_size=32,buffer_size=None,window_size=32,window_shift=16,cache=True):

  def batch_window(window):
    return window.batch(window_size+1)

  def to_window(chorale):
    dataset = tf.data.Dataset.from_tensor_slices(chorale)
    dataset = dataset.window(window_size+1, window_shift, drop_remainder=True)
    return dataset.flat_map(batch_window)
  chorales = tf.ragged.constant(chorales, ragged_rank=1)
  dataset = tf.data.Dataset.from_tensor_slices(chorales)
  dataset = dataset.flat_map(to_window).map(preprocess)
  if cache:
    dataset = dataset.cache()
  if buffer_size:
    dataset = dataset.shuffle(buffer_size)
  dataset = dataset.batch(batch_size)
  dataset = dataset.map(create_target)
  return dataset.prefetch(1)

train_set = bach_dataset(train_chorales, buffer_size=1000)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)

n_embedding_dim = 5
model = tf.keras.models.Sequential([
    tf.keras.layers.Embedding(input_dim=n_notes,output_dim=n_embedding_dim,input_shape=[None]),
    tf.keras.layers.Conv1D(32,kernel_size=2,padding='causal',activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Conv1D(48,kernel_size=2,padding='causal',activation='relu', dilation_rate=2),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Conv1D(64,kernel_size=2,padding='causal',activation='relu',dilation_rate=4),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Conv1D(96,kernel_size=2,padding='causal',activation='relu',dilation_rate=8),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.GRU(256,return_sequences=True),
    tf.keras.layers.Dense(n_notes,activation='softmax')
])
model.summary()

optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)
model.compile(loss="sparse_categorical_crossentropy", optimizer=optimizer,
              metrics=["accuracy"])
model.fit(train_set, epochs=20, validation_data=valid_set)

model.save("my_bach_model.h5")
model.evaluate(test_set)

def generate_chorale(model,seed_chords,length):
  arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
  arpegio = tf.reshape(arpegio,[1,-1])
  for chord in range(length):
    for note in range(4):
      next_note = np.argmax(model.predict(arpegio),axis=-1)[:1, -1:]
      arpegio = tf.concat([arpegio,next_note] ,axis=1)
  arpegio = tf.where(arpegio == 0, arpegio, arpegio+min_note-1)
  return tf.reshape(arpegio,[-1,4])

seed_chord = test_chorales[2][:8]
play_chords(seed_chord,filepath='test_seed.wav',amplitude=0.2,)

new_chorale = generate_chorale(model, seed_chord, 56)
play_chords(new_chorale)

def generate_chorale_v2(model, seed_chords, length, temperature=1):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            next_note_probas = model.predict(arpegio)[0, -1:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=1)
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])

new_chorale_v2_cold = generate_chorale_v2(model,seed_chord,56,temperature=0.8)
play_chords(new_chorale_v2_cold, filepath="bach_cold.wav",amplitude=0.4)

new_chorale_v2_medium = generate_chorale_v2(model,seed_chord,56,temperature=1)
play_chords(new_chorale_v2_medium, filepath="bach_medium.wav",amplitude=0.4)

new_chorale_v2_hot= generate_chorale_v2(model,seed_chord,56,temperature=1.5)
play_chords(new_chorale_v2_hot, filepath="bach_hot.wav",amplitude=0.4)

